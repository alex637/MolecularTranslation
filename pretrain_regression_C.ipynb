{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict()\n",
    "cfg['n_channels'] = 50\n",
    "cfg['input_channels'] = 1\n",
    "cfg['output_channels'] = 1 # 11\n",
    "cfg['dropout'] = 0.2\n",
    "cfg['fc_intermediate_len'] = 100 # ? 128\n",
    "cfg['x_size'] = 150 # ? such order of dims\n",
    "cfg['y_size'] = 300 # ? such order of dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pic(image_id, is_train=True):\n",
    "    _ = 'train' if is_train else 'test'\n",
    "    directory = 'original_data/{}/{}/{}/{}/'.format(_, image_id[0], image_id[1], image_id[2])\n",
    "    return torch.Tensor(imageio.imread(directory + image_id + '.png') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only Carbon counts\n",
    "class PretrainRegressionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file, y_file, x_size=256, y_size=256):\n",
    "        self.data = pd.read_csv(file)\n",
    "        self.y = torch.tensor(np.load(y_file)[:,1],\n",
    "                              dtype=torch.float32).unsqueeze(1) # only C\n",
    "        self.y.to(device)\n",
    "        self.x_size = x_size\n",
    "        self.y_size = y_size\n",
    "        self.resize = Resize(size=(x_size,y_size))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pic = load_pic(self.data['image_id'][index]).unsqueeze(0) # C=1 channel\n",
    "        pic = self.resize(pic) / 255.\n",
    "        y = self.y[index]\n",
    "        return pic, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndataset = PretrainRegressionDataset('data/pretrain2/data_train_small.csv',\\n                                    'data/pretrain2/atom_counts_train_small.npy',\\n                                     x_size=cfg['x_size'], y_size=cfg['y_size'])\\n\\ncount = 0\\nfor elem in dataset:\\n    if count > 5: break\\n    print(elem[0].shape)\\n    print(elem)\\n    count += 1\\n\\ndel dataset\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dataset = PretrainRegressionDataset('data/pretrain2/data_train_small.csv',\n",
    "                                    'data/pretrain2/atom_counts_train_small.npy',\n",
    "                                     x_size=cfg['x_size'], y_size=cfg['y_size'])\n",
    "\n",
    "count = 0\n",
    "for elem in dataset:\n",
    "    if count > 5: break\n",
    "    print(elem[0].shape)\n",
    "    print(elem)\n",
    "    count += 1\n",
    "\n",
    "del dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in1, out1, in2, out2, st1=1, st2=1, dropout=0.2):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        # nn.Conv2D(in_channels, out_channels, kernel_size=(,), stride)\n",
    "        self.conv1 = nn.Conv2d(in1, out1, kernel_size=(2,2), stride=st1)\n",
    "        self.conv2 = nn.Conv2d(in2, out2, kernel_size=(2,2), stride=st2)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.pool  = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.bn    = nn.BatchNorm2d(out2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock3(nn.Module):\n",
    "    def __init__(self, in1, out1, in2, out2, st1=1, st2=1, dropout=0.2):\n",
    "        super(ConvBlock3, self).__init__()\n",
    "        # nn.Conv2D(in_channels, out_channels, kernel_size=(,), stride)\n",
    "        self.conv1 = nn.Conv2d(in1, out1, kernel_size=(2,3), stride=st1)\n",
    "        self.conv2 = nn.Conv2d(in2, out2, kernel_size=(2,3), stride=st2)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.pool  = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.bn    = nn.BatchNorm2d(out2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock1(nn.Module):\n",
    "    def __init__(self, in1, out1, in2, out2, st1=1, st2=1, dropout=0.2):\n",
    "        super(ResBlock1, self).__init__()\n",
    "        # nn.Conv2D(in_channels, out_channels, kernel_size=(,), stride)\n",
    "        self.conv1 = nn.Conv2d(in1, out1, kernel_size=(2,3), stride=st1)\n",
    "        self.conv2 = nn.Conv2d(in2, out2, kernel_size=(2,3), stride=st2)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.pool  = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.bn1   = nn.BatchNorm2d(out2)\n",
    "        self.bn2   = nn.BatchNorm2d(out2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x.clone()\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            \n",
    "        x += residual\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        n_ch = config['n_channels']\n",
    "        i_ch = config['input_channels']\n",
    "        f1_len = config['fc_intermediate_len']\n",
    "        f2_len = config['output_channels'] # len(y)\n",
    "        self.conv_block_1 = ConvBlock3(in1=i_ch, out1=n_ch, in2=n_ch, out2=n_ch, st1=2)\n",
    "        self.conv_block_2 = ConvBlock( in1=n_ch, out1=n_ch, in2=n_ch, out2=n_ch)\n",
    "        self.conv_block_3 = ConvBlock3(in1=n_ch, out1=n_ch, in2=n_ch, out2=n_ch)\n",
    "        self.conv_block_4 = ConvBlock( in1=n_ch, out1=n_ch, in2=n_ch, out2=n_ch)\n",
    "        self.conv_block_5 = ConvBlock( in1=n_ch, out1=n_ch, in2=n_ch, out2=n_ch)\n",
    "        self.fc1 = nn.Linear(n_ch * 12, f1_len) # FIXME dimensions # 612\n",
    "        self.fc2 = nn.Linear(f1_len, f2_len)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout=nn.Dropout(config['dropout'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = self.conv_block_4(x)\n",
    "        print('\\n', x.shape, '\\n', sep='')\n",
    "        x = self.conv_block_5(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device=torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(cnn, data_loader, loss_type='mse'):\n",
    "    if loss_type =='mse': \n",
    "        Loss = nn.MSELoss()\n",
    "    elif loss_type == 'mae':\n",
    "        Loss = nn.L1Loss()\n",
    "    else:\n",
    "        return 'ERROR'\n",
    "\n",
    "    loss = 0.0\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            predictions = cnn(x_batch)\n",
    "            loss += Loss(predictions, y_batch).item()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(data_loader, cnn, optimizer, criterion):\n",
    "    running_loss = 0.0\n",
    "    for x_batch, y_batch in tqdm(data_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = cnn(x_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print('running_loss after epoch is', running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset_train, dataset_test, cnn, n_epochs, batch_size):\n",
    "    data_train_loader = torch.utils.data.DataLoader(dataset_train, batch_size,\n",
    "                                                   num_workers=10, persistent_workers=False,pin_memory=True)\n",
    "    data_test_loader  = torch.utils.data.DataLoader(dataset_test, batch_size, num_workers=2,pin_memory=False)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    #criterion = nn.L1Loss()\n",
    "    #criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=0.01)\n",
    "    for i in range(n_epochs):\n",
    "        print('Starting epoch {}'.format(i))\n",
    "        cnn.train()\n",
    "        train_epoch(data_train_loader, cnn, optimizer, criterion)\n",
    "        #train_loss = 'dummy'#calc_loss(cnn, data_train_loader)\n",
    "        test_loss = calc_loss(cnn, data_test_loader, 'mae')\n",
    "        #print('Train loss:\\t', train_loss)\n",
    "        print('Test loss (MAE):\\t', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dataset_train = PretrainRegressionDataset('data/pretrain2/data_train.csv',\n",
    "                                          'data/pretrain2/atom_counts_train.npy',\n",
    "                                           x_size=cfg['x_size'], y_size=cfg['y_size'])\n",
    "dataset_test = PretrainRegressionDataset('data/pretrain2/data_test.csv',\n",
    "                                          'data/pretrain2/atom_counts_test.npy',\n",
    "                                          x_size=cfg['x_size'], y_size=cfg['y_size'])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dataset_train = PretrainRegressionDataset('data/pretrain2/data_train_small.csv',\n",
    "                                          'data/pretrain2/atom_counts_train_small.npy',\n",
    "                                           x_size=cfg['x_size'], y_size=cfg['y_size'])\n",
    "dataset_test = PretrainRegressionDataset('data/pretrain2/data_test_small.csv',\n",
    "                                          'data/pretrain2/atom_counts_test_small.npy',\n",
    "                                          x_size=cfg['x_size'], y_size=cfg['y_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNNEncoder(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet import some_model, ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = some_model(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom torchvision.models import resnet34\\ncnn1 = resnet34(pretrained=False)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from torchvision.models import resnet34\n",
    "cnn1 = resnet34(pretrained=False)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (i_downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (i_downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (i_downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (i_downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (batch_norm3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:54<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_loss after epoch is 6300.271611690521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (MAE):\t 783.1421613693237\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:54<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_loss after epoch is 4503.52955698967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (MAE):\t 361.4475269317627\n",
      "CPU times: user 4min 45s, sys: 1min 34s, total: 6min 19s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(dataset_train, dataset_test, resnet, n_epochs=2, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.347800254821777 22.187238693237305 26.297483444213867 12.539535522460938 26.771360397338867 21.815122604370117\n",
      "13.0 19.0 21.0 11.0 21.0 16.0\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "trues = []\n",
    "resnet.eval()\n",
    "for index, (_, __) in enumerate(dataset_test):\n",
    "    if index > 5:\n",
    "        break\n",
    "    with torch.no_grad():\n",
    "        pred = resnet(_.unsqueeze(0).to(device)).item()\n",
    "    preds.append(pred)\n",
    "    trues.append(__.item())\n",
    "        \n",
    "print(*preds)\n",
    "print(*trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'data/resnet_v1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
